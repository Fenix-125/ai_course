{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenix/pr/ai_course/lab_1/venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/fenix/pr/ai_course/lab_1/venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "class MNISTpairs(data.Dataset):\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset in pairs of similar(positive)/non-similar(negative) pairs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mnist_dataset):    \n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.transform = self.mnist_dataset.transform\n",
    "        self.labels = self.mnist_dataset.train_labels\n",
    "        self.data = self.mnist_dataset.train_data                \n",
    "        # indices of images for each class\n",
    "        self.class_idx = [np.where(self.labels==x)[0] for x in range(0,10)]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # anchor image\n",
    "        img1, label1 = self.data[index], self.labels[index].item()\n",
    "        # draw another positive (1) or negative (0) image\n",
    "        pair_label = np.random.randint(0, 2)\n",
    "        \n",
    "        if pair_label == 1:\n",
    "            # choose an image with the same label as the anchor - avoid itself\n",
    "            index2 = index\n",
    "            while index2 == index:\n",
    "                index2 = np.random.choice(self.class_idx[label1])\n",
    "            img2 = self.data[index2]\n",
    "        else:\n",
    "            # choose an image with the different label than the anchor \n",
    "            img2 = self.data[np.random.choice(self.class_idx[ np.random.choice(np.setdiff1d(range(0,10), label1))])]\n",
    "            \n",
    "        img1 = Image.fromarray(img1.numpy(), mode='L')\n",
    "        img2 = Image.fromarray(img2.numpy(), mode='L')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        \n",
    "        return (img1, img2), pair_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    \n",
    "# mnist dataset structure - test part\n",
    "mnist_dataset_test = datasets.MNIST('vs3ex1data/mnist_data', train=False, transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ]))\n",
    "    \n",
    "# mnist dataset structure - train part\n",
    "mnist_dataset_train = datasets.MNIST('vs3ex1data/mnist_data', train=True, transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ]))\n",
    "            \n",
    "# mnist dataset in positive/negative pairs structure \n",
    "mnist_dataset_train_pairs = MNISTpairs(mnist_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2n(x, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Vector L2 normalization \n",
    "    \"\"\"\n",
    "    return x / (torch.norm(x, p=2, dim=1, keepdim=True) + eps).expand_as(x)\n",
    "\n",
    "class MnistNetEmb(nn.Module):\n",
    "    \"\"\"\n",
    "    Liteweight network architecture for the Mnist dataset (digit) to extract descriptors/embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MnistNetEmb, self).__init__()\n",
    "\n",
    "        # fully convolutional part\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, 4, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True)            \n",
    "        )\n",
    "        \n",
    "        # embedding network, FC layers\n",
    "        self.embedder = nn.Sequential(\n",
    "            nn.Linear(16*4,16)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.embedder(x.view(-1,x.size(-3)*x.size(-2)*x.size(-1)))\n",
    "        return l2n(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, train_loader, optimizer, margin = 0.9):\n",
    "    \"\"\"\n",
    "    Training of an epoch with Contrastive loss and training pairs\n",
    "    model: network\n",
    "    train_loader: train_loader loading pairs of positive/negative images and pair-label in batches. \n",
    "    optimizer: optimizer to use in the training\n",
    "    margin: loss margin\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    all_neg_dist = torch.Tensor()\n",
    "    all_pos_dist = torch.Tensor()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # extract descriptor for anchor and the corresponding pos/neg images\n",
    "        v1, v2 = model(data[0]), model(data[1])\n",
    "        \n",
    "        # compute the contrastive loss\n",
    "        distances = (v2 - v1).pow(2).sum(1).sqrt()        \n",
    "        loss = 0.5 * (target.float() * distances.pow(2) + (1-target).float()*F.relu(margin - distances).pow(2))\n",
    "        \n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        all_neg_dist = torch.cat((all_neg_dist, distances[torch.nonzero(1-target)].view(-1))) # for statistics\n",
    "        all_pos_dist = torch.cat((all_pos_dist, distances[torch.nonzero(target)].view(-1))) # for statistics\n",
    "        total_loss = total_loss + loss.sum().data.numpy()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('[{}/{} ({:.0f}%)]\\tBatch loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.mean()))\n",
    "    print('Epoch average loss {:.6f}'.format(total_loss/len(train_loader.dataset)))\n",
    "\n",
    "    plt.hist(all_pos_dist.data.numpy(), 20, alpha = 0.5, label = 'pos')\n",
    "    plt.hist(all_neg_dist.data.numpy(), 20, alpha = 0.5, label = 'neg')\n",
    "    plt.title('Distribution of distances for positive and negative pairs')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def test(model, test_loader, step = 100):\n",
    "    \"\"\"\n",
    "    Compute accuracy on the test set\n",
    "    model: network\n",
    "    test_loader: test_loader loading images and labels in batches\n",
    "    step: step to iterate over images (for faster evaluation)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    des = torch.Tensor()\n",
    "    labels = torch.LongTensor()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        des = torch.cat((des, model(data)))\n",
    "        labels = torch.cat((labels, target))\n",
    "    \n",
    "    # compute all pair-wise distances\n",
    "    cdistances = cdist(des.data.numpy(), des.data.numpy(), 'euclidean')\n",
    "        \n",
    "    # find rank of closest positive image (using each descriptor as a query)\n",
    "    minrank_positive = []\n",
    "    for i in range(0,len(cdistances),step):\n",
    "        idx = np.argsort(cdistances[i])\n",
    "        minrank_positive.append( np.min([j for (j,x) in enumerate(labels[idx[1:-1]]) if x==labels[i]]) )\n",
    "    \n",
    "    print('Validation: At-least-1-pos@1 {:.3f}'.format((np.array(minrank_positive) <1).mean()))\n",
    "    print('Validation: At-least-1-pos@3 {:.3f}'.format((np.array(minrank_positive) <3).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the randomly initialized network\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-28690c5c7c3b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Validating the randomly initialized network'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# test the randomly initialized network\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-c2fa0030220c>\u001B[0m in \u001B[0;36mtest\u001B[0;34m(model, test_loader, step)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcdistances\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         \u001B[0midx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcdistances\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0mminrank_positive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Validation: At-least-1-pos@1 {:.3f}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mminrank_positive\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-c2fa0030220c>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcdistances\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         \u001B[0midx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcdistances\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0mminrank_positive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Validation: At-least-1-pos@1 {:.3f}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mminrank_positive\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pr/ai_course/lab_1/venv/lib/python3.8/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(i)\u001B[0m\n\u001B[1;32m    454\u001B[0m                           \u001B[0;34m'iterations executed (and might lead to errors or silently give '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    455\u001B[0m                           'incorrect results).', category=RuntimeWarning)\n\u001B[0;32m--> 456\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    457\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    458\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__hash__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# loader of the training set in pairs\n",
    "train_loader_pairs = torch.utils.data.DataLoader(mnist_dataset_train_pairs,batch_size=64, shuffle=True)\n",
    "#loader of the test set (no pairs here)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dataset_test,batch_size=512, shuffle=False)\n",
    "\n",
    "model = MnistNetEmb() # initialize the network\n",
    "\n",
    "print('Validating the randomly initialized network')\n",
    "test(model, test_loader) # test the randomly initialized network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print('Training with Contrastive loss and training pairs')\n",
    "# train with contrastive loss\n",
    "contrastive_margin = 0.9\n",
    "for epoch in range(1, 10 + 1):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        train2(model, train_loader_pairs, optimizer, contrastive_margin)\n",
    "        test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}