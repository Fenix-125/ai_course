{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Unsupervised feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this problem you will see how unsupervised learning can help you train better models even with labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_x = 32 # width of image\n",
    "image_y = 32 # height of image\n",
    "patch_dim = 8 # height/width of a patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "\n",
    "    def __init__(self,data,label,patches):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        -----------\n",
    "        Takes image related data, called on image creation.\n",
    "        \"\"\"\n",
    "        self.label = label # image label\n",
    "        self.patches = patches.transpose().tolist()\n",
    "        \n",
    "        self.__img_data = data\n",
    "\n",
    "    def view(self):\n",
    "        \"\"\"\n",
    "        Function: View\n",
    "        --------------\n",
    "        Call function to view RGB image\n",
    "        \"\"\"\n",
    "        from PIL import Image\n",
    "        im = Image.fromarray(self.__img_data)\n",
    "        im = im.resize((128,128),Image.BILINEAR)\n",
    "        im.show()\n",
    "\n",
    "    def get_label(self):\n",
    "        \"\"\"\n",
    "        Function: Label\n",
    "        ---------------\n",
    "        Returns label of image\n",
    "        \"\"\"\n",
    "        return self.label\n",
    "\n",
    "    def get_patches(self):\n",
    "        \"\"\"\n",
    "        Function: Patches\n",
    "        -----------------\n",
    "        Returns list of patch vectors. Each patch length patch_size\n",
    "        \"\"\"\n",
    "        return self.patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_helper(name,m):\n",
    "    channels = 3\n",
    "    patch_dim = 8\n",
    "    patches_per_image = (image_x/patch_dim)*(image_y/patch_dim)\n",
    "\n",
    "    images = np.fromfile('data/CIFAR/images_'+name+'.bin',dtype=np.uint8)\n",
    "    images = images.reshape((m,image_x,image_y,channels))\n",
    "\n",
    "    patches = np.fromfile('data/CIFAR/patches_'+name+'.bin',dtype=np.float32)\n",
    "    patches = patches.reshape((patch_dim**2,-1))\n",
    "\n",
    "    labels = np.fromfile('data/CIFAR/labels_'+name+'.bin',dtype=np.uint8)\n",
    "\n",
    "    image_list = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_list.append(Image(images[i,...],labels[i],\n",
    "            patches[:,int(i*patches_per_image):int((i+1)*patches_per_image)]))\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def view_helper(patches,num):\n",
    "    from PIL import Image\n",
    "    \n",
    "    xnum = int(np.sqrt(num))\n",
    "    if xnum**2 == num:\n",
    "        ynum = xnum\n",
    "    else:\n",
    "        ynum = xnum+1\n",
    "\n",
    "    imDim = 50\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        patches = patches-np.min(patches)\n",
    "        patches = patches/np.max(patches)\n",
    "        patchDim = patches.shape[0]\n",
    "        image = np.zeros(((patchDim+1)*ynum+1,(patchDim+1)*xnum+1))\n",
    "        for i in range(ynum):\n",
    "            for j in range(xnum):\n",
    "                imnum = i*xnum+j\n",
    "                if imnum>=num:\n",
    "                    break\n",
    "                ax = plt.subplot2grid((ynum,xnum),(i,j))\n",
    "                ax.imshow(patches[:,:,i*xnum+j].squeeze(), cmap = plt.get_cmap('gray'))\n",
    "                ax.axes.get_xaxis().set_visible(False)\n",
    "                ax.axes.get_yaxis().set_visible(False)\n",
    "                \n",
    "        plt.subplots_adjust(wspace=-.5 ,hspace=0.2)\n",
    "        plt.show()\n",
    "        return\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # rescale to be [0-255]\n",
    "    patches = patches-np.min(patches)\n",
    "    patches = 255*patches/np.max(patches)\n",
    "\n",
    "    newpatches = np.empty((imDim,imDim,num))\n",
    "\n",
    "    for p in range(num):\n",
    "        patch = patches[:,:,p].squeeze().copy()\n",
    "        im = Image.fromarray(patch)\n",
    "        im = im.resize((imDim,imDim),Image.BILINEAR)\n",
    "        newpatches[:,:,p] = np.asarray(im.convert('L'))\n",
    "\n",
    "    patches = newpatches\n",
    "    image = np.zeros(((imDim+1)*ynum+1,(imDim+1)*xnum+1))\n",
    "\n",
    "    for i in range(ynum):\n",
    "        for j in range(xnum):\n",
    "            imnum = i*xnum+j\n",
    "            if imnum>=num:\n",
    "                break\n",
    "            image[i*(imDim+1)+1:i*(imDim+1)+imDim+1, \\\n",
    "                  j*(imDim+1)+1:j*(imDim+1)+imDim+1] \\\n",
    "                  = patches[:,:,imnum]\n",
    "    image = Image.fromarray(image, 'L')\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pixel_features(images):\n",
    "    \"\"\"\n",
    "    Extracts raw pixel features for all images.  Returns a 2-D array\n",
    "    of size featDim x numExamples and a vector of labels.\n",
    "    \"\"\"\n",
    "    X = [np.array(image.get_patches()).ravel() for image in images]\n",
    "    X = np.vstack(X).transpose() # feat dim by num samples\n",
    "    # label array\n",
    "    Y = np.array([image.get_label() for image in images])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def view_patches(patches):\n",
    "    \"\"\"\n",
    "    Function: View Patches\n",
    "    ----------------------\n",
    "    Pass in an array of patches (or centroids) in order to view them as\n",
    "    images.\n",
    "    \"\"\"\n",
    "    view_helper(patches.reshape(patch_dim,patch_dim,-1),patches.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_train_images = 2000\n",
    "file_tag = 'train'\n",
    "train_image_list = load_helper(file_tag,num_train_images)\n",
    "\n",
    "num_test_images = 1000\n",
    "file_tag = 'test'\n",
    "test_image_list = load_helper(file_tag,num_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X,train_Y = pixel_features(train_image_list)\n",
    "test_X,test_Y = pixel_features(test_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((1024, 2000), (2000,))"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.77245879e+00 -2.36186966e-01  4.86198068e-02 ... -2.42185146e-01\n",
      "  -1.57253239e-02  9.44859445e-01]\n",
      " [-2.66454482e+00 -1.67018801e-01  1.09784670e-01 ... -1.25524580e-01\n",
      "  -4.30927604e-01  1.60894477e+00]\n",
      " [ 1.04330039e+00 -5.38556993e-01  1.20907120e-01 ... -3.12024087e-01\n",
      "   2.23523572e-01  3.41507196e-01]\n",
      " ...\n",
      " [ 1.45803440e+00  3.45114350e-01  2.76380658e-01 ... -7.04077601e-01\n",
      "   9.04016048e-02  1.22188699e+00]\n",
      " [ 2.40676475e+00 -1.25334633e-03 -8.77847150e-02 ... -2.81709522e-01\n",
      "  -4.84565198e-01  1.68098342e+00]\n",
      " [ 2.08898202e-01 -3.34747881e-02  5.40620685e-02 ... -1.38029903e-01\n",
      "   3.84905010e-01  1.27014351e+00]]\n",
      "\n",
      "[1 1 1 1 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[:10])\n",
    "print(\"\")\n",
    "print(train_Y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train logistic regression on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:\t0.5363004783377863\n",
      "recall_score:\t\t0.5360527663934427\n",
      "f1_score:\t\t0.5345527051496488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = deepcopy(train_X).T, deepcopy(test_X).T, deepcopy(train_Y), deepcopy(test_Y)\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', max_iter=2000).fit(X_train1, y_train1)\n",
    "y_pred_LR = clf1.predict(X_test1)\n",
    "\n",
    "print(f\"precision_score:\\t{precision_score(y_test1, y_pred_LR, average='macro')}\")\n",
    "print(f\"recall_score:\\t\\t{recall_score(y_test1, y_pred_LR, average='macro')}\")\n",
    "print(f\"f1_score:\\t\\t{f1_score(y_test1, y_pred_LR, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train SVM on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:\t0.6307764048496783\n",
      "recall_score:\t\t0.6307633196721312\n",
      "f1_score:\t\t0.6307692307692307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = deepcopy(train_X).T, deepcopy(test_X).T, deepcopy(train_Y), deepcopy(test_Y)\n",
    "\n",
    "clf2 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf2.fit(X_train2, y_train2)\n",
    "y_pred_SVC = clf2.predict(X_test2)\n",
    "\n",
    "print(f\"precision_score:\\t{precision_score(y_test2, y_pred_SVC, average='macro')}\")\n",
    "print(f\"recall_score:\\t\\t{recall_score(y_test2, y_pred_SVC, average='macro')}\")\n",
    "print(f\"f1_score:\\t\\t{f1_score(y_test2, y_pred_SVC, average='macro')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train XGBoost on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:\t0.7040144520272982\n",
      "recall_score:\t\t0.7033971567622951\n",
      "f1_score:\t\t0.7034769333103594\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = deepcopy(train_X).T, deepcopy(test_X).T, deepcopy(train_Y), deepcopy(test_Y)\n",
    "\n",
    "clf3 = XGBClassifier().fit(X_train3, y_train3)\n",
    "y_pred_LR = clf3.predict(X_test1)\n",
    "\n",
    "print(f\"precision_score:\\t{precision_score(y_test3, y_pred_LR, average='macro')}\")\n",
    "print(f\"recall_score:\\t\\t{recall_score(y_test3, y_pred_LR, average='macro')}\")\n",
    "print(f\"f1_score:\\t\\t{f1_score(y_test3, y_pred_LR, average='macro')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Learning better features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Instead of hand-designing better features let us see if we can learn them directly from data.\n",
    "Each image is a 32x32 grid of pixels. We will divide the image into sixteen 8x8 \"patches\".\n",
    "Next, we will use K-means to cluster all the patches into centroids. These centroids will then\n",
    "allow us to use a better feature representation of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us see how we can get patches from the images and visualize them. Make sure you understand the\n",
    "dimensions of every array and what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_images = 2\n",
    "patches = np.hstack([np.array(image.get_patches()).transpose() for image in train_image_list[:num_images]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 32)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 30 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_patches(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run k-means from scikit-learn to group all patches into clusters. Initially, pick the number\n",
    "of clusters according to your best guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 16000)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = 1000\n",
    "patches = np.hstack([np.array(image.get_patches()).transpose() for image in train_image_list[:num_images]])\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=16)\n",
    "model.fit(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, visualize the centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "centroids = np.array(model.cluster_centers_) # Please use this variable name for the array of centroids\n",
    "view_patches(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Representing examples in a new way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, you have the centroids defining similar groups in your patches. Represent every image in your training and test set in distances between the patch and each centroid. For example, if you used 10 clusters and each image has 16 patches, new representation of the image will be a vector of 160 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train all three classifiers from the above (logistic regression, SVM and XGBoost) on the new image representation. Report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Getting the best out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In industry, we typically try to get as much as possible out of the data we have. Try different number of clusters and different configuration of the models and report the best accuracy you got on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}